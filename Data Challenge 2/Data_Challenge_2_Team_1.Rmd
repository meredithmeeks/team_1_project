---
title: "QMSS5069 Data Challenge 2"
author: "Team 1 - Svyatoslav Andriyishen, Shilpa Sure, Meredith Meeks, Kai Huo, Hannah Hao"
date: "March 22, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data Challenge 2

1. Ask two (2) questions that might help you understand better the dynamics of violence contained on our datas et. Apply one algorithm per question and share your insights from each analysis. [50 pts]  Remember: a non-finding is also a finding! It tells you whether a question is worth pursuing further or not.
	* perform the necessary transformations in your data - if any are needed, and explain why you did that
	* show the output from your analysis in a consumable form
	* be explicit about the limitations of your anaylisis, due to estimation or to the data itself
	* did you find something interesting? what is that? does your finding suggest this question is worth pursuing further? why or why not?
	* if you did not find something interesting, explain why, and whether there is some additional information that would help in answering your question
	* provide your code, and a single visualization per question that summarizes your finding 
	* phrase your finding for each question in two ways: 
		* one sentence that summarizes your insight
		* one paragraph that reflects all nuance in your insight 
	* make sure to also include your code 

2. Formulate two (2) conditional hypotheses that you seek to investigate with the data. One of your hypotheses should condition on two variables (as the example on the slides), and the other should condition on three variables. [50 pts]
    * formulate each one of your hypotheses explicitly in substantive terms (as opposed to statistical terms) using 2-3 lines at most
	* show exactly how each one of your hypotheses translates into the marginal effect that you will seek to estimate from the data 
	* show the output from your analysis in a consumable form
	* show all your computations to estimate the corresponding marginal effect and its standard error
	* be explicit in your assumptions
	* be explicit in the limitations of your inferences
	* phrase your finding for each question in two ways: 
		* one sentence that summarizes your insight
		* one paragraph that reflects all nuance in your insight 
	* make sure to also include your code 

```{r Libraries, message=FALSE}
if (!require("dplyr")) {
 install.packages("dplyr", dependencies = TRUE)
 library(dplyr)
 }
if (!require("tidyr")) {
 install.packages("tidyr", dependencies = TRUE)
 library(tidyr)
 }
if (!require("ggplot2")) {
 install.packages("ggplot2", dependencies = TRUE)
 library(ggplot2)
 }
if (!require("readr")) {
 install.packages("readr", dependencies = TRUE)
 library(readr)
}
if (!require("pscl")) {
 install.packages("pscl", dependencies = TRUE)
 library(pscl)
 }
if (!require("MASS")) {
 install.packages("MASS", dependencies = TRUE)
 library(MASS)
 }
if (!require("boot")) {
 install.packages("boot", dependencies = TRUE)
 library(boot)
 }
if (!require("AICcmodavg")) {
 install.packages("AICcmodavg", dependencies = TRUE)
 library(AICcmodavg)
}
if (!require("lubridate")) {
 install.packages("lubridate", dependencies = TRUE)
 library(lubridate)
}
if (!require("randomForest")) {
 install.packages("randomForest", dependencies = TRUE)
 library(randomForest)
}
```

```{r Load Data}
Confrontations <- read.csv("AllViolenceData_170216.csv")
Confrontations$date <- as.Date(Confrontations$date)
# take out global.id, event.id, unix.timestamp
# these unimformative variables may influence the models
Confrontations <- Confrontations[ , -c(which(colnames(Confrontations) == "global.id"),
                                       which(colnames(Confrontations) == "event.id"),
                                       which(colnames(Confrontations) == "unix.timestamp"))]
# str(Confrontations)
```



#### Question 1


##### Part 1

We are looking for the effect of independent variables on the number of non-law enforcement persons (civilians and organized crime members) wounded.

```{r}
civ_oc_wounded <- Confrontations$organized.crime.wounded + Confrontations$civilian.wounded
Confrontations_2 <- cbind(Confrontations, civ_oc_wounded)

ggplot(Confrontations_2, aes(civ_oc_wounded)) + 
  geom_bar(fill = "white", colour = "darkgreen") + theme_bw() + 
  xlab("Civilians and Organized Crime Wounded") + ylab("Count") + 
  facet_wrap(~ perfect.lethality)

# mean
mean(Confrontations_2$civ_oc_wounded)

# variance
var(Confrontations_2$civ_oc_wounded)
```

We notice two things about the data - one, there are a large number of cases in which zero civilians or organized crime members were wounded. Second, the variance of the distribution (1.55) is much larger than the mean (0.44).

In cases in which the variable is a count, there is a large number of zeros, and the variance is much larger than the mean, it may be better to use a zero-inflated negative binomial regression, rather than a linear regression model. 

For comparison, let us first look at the performance of a linear regression model. We have created one independent variables to reduce collinearity - arms_seized which includes the number of long guns seized and small arms seized. We are also including variables for the presence of the army, navy, afi, federal police, municipal police, ministerial police, and state police. 

Here is the linear model:

```{r}
#independent variables:
Confrontations_2$arms_seized <- Confrontations_2$long.guns.seized + Confrontations_2$small.arms.seized
#Confrontations_2$cart_clips_seized <- Confrontations_2$cartridge.sezied + Confrontations_2$clips.seized
ols_civ_oc_wounded <- glm(civ_oc_wounded ~ arms_seized + vehicles.seized + army + navy + afi + federal.police + municipal.police + ministerial.police + state.police, Confrontations_2, family="gaussian")
summary(ols_civ_oc_wounded)
```

The linear model fit is quite poor - as we saw with the distribution of the dependent variable, there is a high number of zero cases. Now we can look at the same model, but modeled as a zero-inflated negative binomial distribution:

```{r}
znb_civ_oc_wounded <- zeroinfl(civ_oc_wounded ~ arms_seized + vehicles.seized + army + navy + afi + federal.police + municipal.police + ministerial.police + state.police, data = Confrontations_2, dist = "negbin", EM = TRUE)
summary(znb_civ_oc_wounded)
AICc(znb_civ_oc_wounded, return.K = FALSE, second.ord = FALSE)
```

Comparing the AIC values, we can see that the zero-inflated negative binomial model performs much better the linear model. Additionally, since the zero-inflated negative binomial model assumes that zeros are generated by two processes - situations where the only possible outcome is zero, and situations where the count is zero. In the model output, the "Count model coefficients" gives us negative binomial regression coefficients, while the "Zero-inflation model coefficients" output gives is coefficients for predicting excess zeros. 

While the model fit is better with a zero-inflated negative binomial model, limitations arise in the interpretability of the model compared to OLS. The coefficients for our negative binomial model (the "Count model coefficients") are given in log-counts. For example, looking at the coefficient on "army", we can interpret this as saying that confrontations involving the army have a 0.516 lower expected log-count of civilians and organized crime members wounded, holding all other factors constant. Looking at the zero-inflated model coefficients, specifically at the coefficient on "federal.police", the log odds of being an "excessive zero" increase by 2.54 when the federal police are involved - when the federal police are involved, there is a higher likelihood of no wounded civilians or organized crime members. 

For our marginal effects, we are primarily interested in looking at the count model coefficients. In this model, the following variables are siginificant with a p-value less than 0.001: arms_seized, vehicle.seized, army, municipal.police, ministerial.police, and state.police. 

Since log-counts are not very intuitive to understand, we can exponentiate the coefficients to get rid of the log:  

```{r}
exp(coef(znb_civ_oc_wounded))
```

When we exponentiate coefficients, we can understand them as incident rate ratios. Looking at the count model coefficients for our significant predictors, we can interpret them as follows:

- **arms_seized**: Confrontations in which long guns or small arms are seized have an incident rate ratio of civilians and organized crime members wounded that is 1.05 times higher than confrontations where these are not seized, holding all other variables constant. 
- **vehicles.seized**: Confrontations in which vehicles are seized have an incident rate ratio of civilians and organized crime members wounded that is 1.11 times higher than confrontations where these are not seized, holding all other variables constant. . 
- **army**: Confrontations in which the army is involved have an incident rate ratio of civilians and organized crime members wounded that is 0.59 times that of confrontations in which the army is not involved, holding all other variables constant. .
- **municipal.police**: Confrontations in which the municipal police are involved have an incident rate ratio of civilians and organized crime members wounded that is 0.44 times that of confrontations in which the municipal police are not involved, holding all other variables constant. 
- **ministerial.police**: Confrontations in which the ministerial police are involved have an incident rate ratio of civilians and organized crime members wounded that is 0.47 times that of confrontations in which the ministerial police are not involved, holding all other variables constant. 
- **state.police**: Confrontations in which the state police are involved have an incident rate ratio of civilians and organized crime members wounded that is 0.67 times that of confrontations in which the state police are not involved, holding all other variables constant. 

To summarize the main finding from this algorithm:

From a zero-inflated negative binomial model of the number of civilians and organized crime members wounded, we can see that incident rate ratios of this occuring are higher when arms (long guns or small arms) or vehicles are seized, and lower when the army, municipal police, ministerial police, or state police are involved. 

The nuance with this type of model comes with the balance between model fit and interpretability. While the zero-inflated negative binomial distribution fits the model better than the linear model, the coefficients are not as easily interpretable as in a linear model. In our model, the direct coefficients are log counts, and exponentiated we can consider them to be incident rate ratios. This tells us about the relative impact of each variable as a ratio of incidence rates, but this is not as easily interpretable as an OLS coefficient. The finding that we have found, that the rates of civilians and organized crime members wounded is higher in situations where arms or vehicles are seized, is quite interesting and may tell us more about the types of confrontations in which civilians or organized crime members are wounded. We also see that incident rate ratios of woundings are lower with certain types of law enforcement (army, municipal police, ministerial police, state police). Both of these findings are quite interesting and should be pursued further - we can ask questions like do those law enforcement bodies use different policies than others? Or is it a matter of which law enforcement parties are generally involved when arms or vehicles are seized?


##### Part 2

We are using randomForest package to build an algorithm predicing the number of civilians dead in a given confrontaion.

```{r}
# randomForest algorithm

set.seed(34593475)
# may have to use rfImpute to impute missing values but dropping for now

Confrontations_nafix <- Confrontations[ , apply(Confrontations, 2, function(x) !any(is.na(x)))]

summary(Confrontations_nafix$civilian.dead)

rf <- randomForest(x = Confrontations_nafix[ , -which(colnames(Confrontations_nafix) == "civilian.dead")], 
                   y = Confrontations_nafix[ , which(colnames(Confrontations_nafix) == "civilian.dead")], 
                   ntree = 1000, importance = TRUE, proximity = TRUE)

rf

plot(rf$mse)

varImpPlot(rf, main = "Variance Importance Plot",
           cex = .6, pt.cex = .8, pch = 6)
```

For the purposes of running a randomForest algorithm, 11 variables containing missing values had to be excluded from the dataset. These variables included law enforcement agencies' lethality rating variables and "newIndex" variables. 

Although randomForest results are not as interpretable as OLM or ligistic regressions, a high importance of some factors in combination with low MSE and a large portion of the variance explained can be insightful. The variable importance chart also cannot be used to gain definite insight into the causality of the situations, and the explanations below are only conjectures, since the chart only explains the importance of the variables for predicting the number of civilian deaths, and not the value by which each variable influences the number of civilian deaths.

The most important factor in predicting the number of civilians dead in a confrontation is the total number of dead in a confrontations. Interestingly, the number of municipal police dead is also a pretty important variable, perhaps because municipal police is deployed in urban conflicts. It is reasonable to assume that incidents involving the municipal police involve more civilians and therefore, these two factors are related if the confrontations are deadly enough (total number of deaths). However, our model has a pretty high MSE at .55 even after running 1000 trees and only 22% of the variance is explained. This result is high since the summary of the **civilian.dead** variable included above shows that the median value of civilian deaths is 0 and the mean is close to 1. There are too many confrontations involving no deaths in the dataset to meaningfully predict civilian deaths with any accuracy. There also might be explanatory factors not included in the dataset that could improve the model and so, the suggested course of action is to gather more data on the circumstances under which civilian deaths occur in order to improve the model.



#### Question 2


##### Part 1

Following up on the randomForest algorithm above, we are creating a binary variable indicating whether any casualties (**anycasualties**) at all occured during a confrontation and then using a conditional logistic model to estimate the effect of involvement of particular law enforcement agencies and military forces on sustaining casualties in a confrontation in which the **municipal.police** was involved. The hypothesis is that the likelihood of any casualties sustained when municipal police is involved is lower than when the municipal police is accompanied by the navy, army, or federal police, since the assumption is that the municipal police is involved alone in smaller urban matters, whereas the federal and military forces get called in for heavier conflicts.

```{r}

# recode category variables
Confrontations_cat <- Confrontations
Confrontations_cat$anycasualties <- ifelse(Confrontations_cat$category == "no.dead.wounded",
                                        "No", "Yes")
Confrontations_cat$anycasualties <- as.factor(Confrontations_cat$anycasualties)
table(Confrontations_cat$anycasualties)
table(Confrontations_cat$anycasualties, Confrontations$municipal.police)
```

For the purposes of the model, the **category** variable was recoded into **anycasualties** variable to indicate a binary response to whether any casualties at all were sustained in a confrontation. From the table of **anycasualties** responses, we can see that in approximately 57% of confrontations, no casualties at all are sustained. Moreover, when municipal police is not involved, casualties occur around half of the time, but when they are involved, casualties occur much less frequently (see another table above).

```{r}
# fir a logit model
summary(casualties_present <- glm(anycasualties ~ municipal.police + army + navy + federal.police + 
                                    afi + ministerial.police + state.police +
                                    municipal.police*navy + 
                                    municipal.police*army + 
                                    municipal.police*federal.police, 
                                  family = binomial(link = "logit"), data = Confrontations_cat))

# create moderator object with all unique values of conditional variables
# in our case, moderator is (0,1) for all cases
moderator <- c(0, 1)
names(moderator) <- c("not involved", "involved")

# obtain covariance matrix from the logit model for calculations
covMat = vcov(casualties_present)

# marginal effects
marginal_navy <- casualties_present$coefficients["municipal.police"] + 
  casualties_present$coefficients["municipal.police:navy"]*moderator

marginal_army <- casualties_present$coefficients["municipal.police"] + 
  casualties_present$coefficients["municipal.police:army"]*moderator

marginal_fedpolice <- casualties_present$coefficients["municipal.police"] + 
  casualties_present$coefficients["municipal.police:federal.police"]*moderator

# variances
var_navy <- covMat["municipal.police", "municipal.police"] + 
  (moderator^2)*covMat["municipal.police:navy", "municipal.police:navy"] + 
  2*moderator*covMat["municipal.police", "municipal.police:navy"]

var_army <- covMat["municipal.police", "municipal.police"] + 
  (moderator^2)*covMat["municipal.police:army", "municipal.police:army"] + 
  2*moderator*covMat["municipal.police", "municipal.police:army"]

var_fedpolice <- covMat["municipal.police", "municipal.police"] + 
  (moderator^2)*covMat["municipal.police:federal.police", "municipal.police:federal.police"] + 
  2*moderator*covMat["municipal.police", "municipal.police:federal.police"]
  
# standard errors
se_navy = sqrt(var_navy)

se_army = sqrt(var_army)

se_fedpolice = sqrt(var_fedpolice)

# print the results
navy <- matrix(rbind(marginal_navy, se_navy), ncol = 2)
colnames(navy) <- c("no navy", "involving navy")
row.names(navy) <- c("marginal effect", "standard error")

army <- matrix(rbind(marginal_army, se_army), ncol = 2)
colnames(army) <- c("no army", "involving army")
row.names(army) <- c("marginal effect", "standard error")

fedpolice <- matrix(rbind(marginal_fedpolice, se_fedpolice), ncol = 2)
colnames(fedpolice) <- c("no fed police", "involving fed police")
row.names(fedpolice) <- c("marginal effect", "standard error")

navy
army
fedpolice
```

The results are on a logit scale and would involve some confusing calculations to convert them to percentages, so we chose to leave them in logit, except in a plot below, where the results are represented in probability. The numbers are related to increases or decreases in the odds of the dependent variable having a value of 1, which means sustaining casualties in our model.

The important takeaway from the model is that the involvement of any military or federal forces does increase the chances of sustaining casualties in a given confrontation. Tables of side-by-side comparison are provided above (don't forget to add the intercept for the full picture). The coefficients on municipal police and other local forces are statistically significant, as well as that of the federal police and interactions between the municipal police and army or federal police. Surprisingly, the interaction on navy variable is not significant and the standard error is humongous! An explanation is given below with a table that shows that municipal police and the navy were involved in exactly one confrontation together in the entire dataset. It is also surprising that the involvement of the federal police increases the chances of having casualties more than that of the army in combination with the municipal police. The rates of federal police  or army cooperation with municipal police are similar and reasonable (tables not shown). Perhaps federal police mishandles situations more frequently than the army. It is assumed that they both would have jurisdiction over the municipal police.

```{r}
table(Confrontations$municipal.police, Confrontations$navy)
```

```{r}
marginal_effects <- data.frame(c(exp(navy[1,1])/(1+exp(navy[1,1])), exp(army[1,2])/(1+exp(army[1,2])), exp(fedpolice[1,2])/(1+exp(fedpolice[1,2]))), nrow = 3)
row.names(marginal_effects) <- c("municipal police alone", "army", "federal police")
colnames(marginal_effects) <- "value"

marginal_effects

ggplot(marginal_effects, aes(x = row.names(marginal_effects), y = value)) +
  geom_bar(stat = "identity") +
  labs(title = "Probability of Sustaining Casualtieswhen Municipal Police\nCooperates with Other Agencies",
       y = "Increase in Probability of Sustaining Casualties",
       x = "Cooperating Agency") +
  theme_classic()
```

The findings are somewhat in line with the hypothesis, showing that municipal police involvement alone decreases the odds of having casualties, but paired with other forces, the odds are increased. It would be useful to have a variable describing the type of operation carried out to fully explain the findings. For instance, if the federal police is involved in drug busts together with municipal police, while the army is involved in evacuations together with municipal police, and municipal police is involved mainly in petty crimes when alone, it might explain the coefficients we found, as these operations are listed in assumed decreasing order of propability of extreme violence occuring.


##### Part 2

conditional hypothesis: look at the effect of the **arms_seized** (long guns and small arms) and **clips.seized** (cartidges or clips seized) on the number of civilians or organized crime members wounded in events involving the **army**:

```{r}

conditional_ols <- lm(formula = civ_oc_wounded ~ army + arms_seized + clips.seized + 
                        army * arms_seized + army * clips.seized + vehicles.seized + 
                        navy + afi + federal.police + municipal.police + 
                        ministerial.police + state.police, 
                      data = Confrontations_2)
summary(conditional_ols)

# Standard error for interaction between army and arms_seized

# marginal effect
moderator <- c(0, 1)
(marginal_effect_army_arms <- conditional_ols$coefficients["army"] + conditional_ols$coefficients["army:arms_seized"]*moderator)

# variances
covMat = vcov(conditional_ols)
var_army_arms <- covMat["army", "army"] + (moderator^2)*covMat["army:arms_seized", "army:arms_seized"] + 
  2*moderator*covMat["army", "army:arms_seized"]
  
# standard errors
se_army_arms = sqrt(var_army_arms)
se_army_arms

# Standard error for interaction between army and clips.seized

# marginal effect
moderator <- c(0, 1)
(marginal_effect_army_clips <- conditional_ols$coefficients["army"] + conditional_ols$coefficients["army:clips.seized"]*moderator)

# variances
covMat = vcov(conditional_ols)
var_army_clips <- covMat["army", "army"] + (moderator^2)*covMat["army:clips.seized", "army:clips.seized"] + 
  2*moderator*covMat["army", "army:clips.seized"]
  
# standard errors
se_army_clips = sqrt(var_army_clips)
se_army_clips
```

```{r}
ggplot(Confrontations_2, aes(x = arms_seized, y = military.wounded)) + 
  geom_jitter((aes(color=category))) + 
  ggtitle("Number of Arms Seized and Military Wounded") + 
  labs(x="Number of Arms Seized", y="Number of Military Wounded") +
  theme_classic()
```

From the output of the model, we can see that the interaction term between **arms_seized** and **army** is significant with a p-value less than 0.01. The marginal effect of the one additional seized weapon (either long gun or small arms) on the number of civilians or organized crime members in events involving the army is -0.0312 (coefficient on interaction term) added to -0.4094 (coefficient on army), for a total marginal effect of -0.4406. If 100 arms (long guns or small arms) are seized, then the marginal effect is -0.4094 + (100*-0.0314) = -3.529 fewer wounded civilians or organized crime members. The standard error is 0.0458.

Looking at the interaction between **clips_seized** and **army**, we can see that this interaction term is slightly less significant with a p-value less than 0.05. The coefficient on the interaction term is also very small (0.00244). We can interpret this as for every 1000 clips that are seized, the marginal effect on the number of civilans or organized crime members wounded is  -0.4094 + (1000*-0.00244), or 2.0338 more wounded civilians or organized crime members. The standard error is 0.0471. 

Summary of insights:

This is an interesting finding because it seems that the marginal effect of more arms seized when the army is involved is a lower number of wounded among non-law enforcement persons. However, the marginal effect of more clips seized is a higher number of wounded civilians or organized crime members. 

There are several points here that should be considered and investigated further. First, the finding related to arms may make sense in that army may be more equipped than local police to deal with operations that involve large numbers of arms being seized. If they are more prepared for these operations, or if criminals surrender arms more easily when they are faced with the army, there may be fewer people wounded. However, I am curious if the relationship between number of arms seized and number wounded is indeed linear, or if the army is really present at many confrontations where arms or clips are seized. 

The second finding, that the number of clips seized has a positive effect on the number of non-law enforcement persons wounded in confrontations involving the army, is also interesting because it is a different trend than we would expect given the first finding. It may be the case that clips are seized during different types of operations, or the army is generally not involved in these and is not as perpared. More investigation would be needed in this case.